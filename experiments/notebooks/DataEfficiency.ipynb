{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and pre-definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "MAIN_PATH = r'/home/luis-felipe'\n",
    "DATA_PATH = os.path.join(MAIN_PATH,'data')\n",
    "PATH_MODELS = os.path.join(MAIN_PATH,'torch_models')\n",
    "FIGS_PATH = os.path.join(MAIN_PATH,'results','figs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Define o computador utilizado como cuda (gpu) se existir ou cpu caso contr√°rio\n",
    "print(torch.cuda.is_available())\n",
    "dev = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "torch.set_default_dtype(torch.float64)\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '..')\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import models\n",
    "from utils import measures,metrics\n",
    "from data_utils import upload_logits, split\n",
    "import pNormSoftmax\n",
    "from collections import defaultdict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ARC = 'wide_resnet50_2'\n",
    "DATASET = 'ImageNet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits,labels = upload_logits(MODEL_ARC,DATASET,PATH_MODELS, \n",
    "                            split = 'test', device = dev)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAL_SIZE = 0.1 #Size of total hold-out samples 0.1 = 5000)\n",
    "N_SPLITS_VAL_TEST = 5 #number of experiments of different splits of validation and test\n",
    "N_SPLIT_SUB_VAL = 5 #How many experiments for each random subset of the holdout\n",
    "SIZES_SUB = np.arange(0.02,1.0,0.02) #Hold-out sizes\n",
    "\n",
    "METRIC = metrics.AURC #metric to be optimzied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_1 = []\n",
    "exp_1_opt = defaultdict(list)\n",
    "for r1 in range(N_SPLITS_VAL_TEST):\n",
    "    logits_val,labels_val,logits_test,labels_test = split.split_logits(logits,labels,VAL_SIZE)\n",
    "    loss_test = measures.wrong_class(logits_test,labels_test).float()\n",
    "    T_star = pNormSoftmax.optimize.T(logits_test,loss_test, METRIC)\n",
    "    p_star = pNormSoftmax.optimize.p(logits_test,loss_test, METRIC)\n",
    "    pT_star = pNormSoftmax.optimize.p_and_beta(logits_test,loss_test,METRIC)\n",
    "    exp_1_opt['baseline'].append(metrics.AUROC(loss_test,measures.MSP(logits_test)))\n",
    "    exp_1_opt['T'].append(metrics.AUROC(loss_test,measures.MSP(logits_test.div(T_star))))\n",
    "    exp_1_opt['p'].append(metrics.AUROC(loss_test,pNormSoftmax.pNormSoftmax(logits_test,p_star,None)))\n",
    "    exp_1_opt['pT'].append(metrics.AUROC(loss_test,pNormSoftmax.pNormSoftmax(logits_test,pT_star[0],pT_star[1])))\n",
    "\n",
    "    exp_2 = []\n",
    "    for r2 in range(N_SPLITS_VAL_TEST):\n",
    "        exp_3 = defaultdict(list)\n",
    "        for val_size_sub in SIZES_SUB:\n",
    "            logits_sub,labels_sub = split.split_logits(logits_val,labels_val,val_size_sub)[:2]\n",
    "            loss_sub = measures.wrong_class(logits_sub,labels_sub).float()\n",
    "            T = pNormSoftmax.optimize.T(logits_sub,loss_sub, METRIC)\n",
    "            p = pNormSoftmax.optimize.p(logits_sub,loss_sub, METRIC)\n",
    "            pT  = pNormSoftmax.optimize.p_and_beta(logits_sub,loss_sub,METRIC)\n",
    "            exp_3['T'].append(metrics.AUROC(loss_test,measures.MSP(logits_test.div(T))))\n",
    "            exp_3['p'].append(metrics.AUROC(loss_test,pNormSoftmax.pNormSoftmax(logits_test,p,pNormSoftmax.beta_heuristic(logits_sub,p))))\n",
    "            exp_3['pT'].append(metrics.AUROC(loss_test,pNormSoftmax.pNormSoftmax(logits_test,pT[0],pT[1])))\n",
    "        exp_2.append(exp_3)\n",
    "\n",
    "    # when val_size_sub is 1.0, there is no need to run the experiment 5 times, since there is only 1 possible split.\n",
    "    #Thus, the results for 1.0 are calculated separately to save time\n",
    "    loss_val = measures.wrong_class(logits_val,labels_val).float()\n",
    "    T = pNormSoftmax.optimize.T(logits_val,loss_val, METRIC)\n",
    "    p = pNormSoftmax.optimize.p(logits_val,loss_val, METRIC)\n",
    "    pT  = pNormSoftmax.optimize.p_and_beta(logits_val,loss_val,METRIC)\n",
    "    for l in exp_2:\n",
    "        l['T'].append(metrics.AUROC(loss_test,measures.MSP(logits_test.div(T))))\n",
    "        l['p'].append(metrics.AUROC(loss_test,pNormSoftmax.pNormSoftmax(logits_test,p,None)))\n",
    "        l['pT'].append(metrics.AUROC(loss_test,pNormSoftmax.pNormSoftmax(logits_test,pT[0],pT[1])))\n",
    "    exp_1.append(exp_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes_sub = labels.size(0)*VAL_SIZE*np.r_[SIZES_SUB,1.0]\n",
    "all_t = []\n",
    "all_p = []\n",
    "all_pT = []\n",
    "for r1 in exp_1:\n",
    "    for r2 in r1:\n",
    "        all_t.append(r2['T'])\n",
    "        all_p.append(r2['p'])\n",
    "        all_pT.append(r2['pT'])\n",
    "all_t = np.array(all_t)\n",
    "all_p = np.array(all_p)\n",
    "all_pT = np.array(all_pT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_T = all_t.mean(0)\n",
    "means_p = all_p.mean(0)\n",
    "means_pT = all_pT.mean(0)\n",
    "\n",
    "std_T = all_t.std(0)\n",
    "std_p = all_p.std(0)\n",
    "std_pT = all_pT.std(0)\n",
    "\n",
    "min_T = all_t.min(0)\n",
    "min_p = all_p.min(0)\n",
    "min_pT = all_pT.min(0)\n",
    "\n",
    "max_T = all_t.max(0)\n",
    "max_p = all_p.max(0)\n",
    "max_pT = all_pT.max(0)\n",
    "\n",
    "baseline_mean = np.mean(exp_1_opt['baseline'])\n",
    "T_opt_mean = np.mean(exp_1_opt['T'])\n",
    "p_opt_mean = np.mean(exp_1_opt['p'])\n",
    "pT_opt_mean = np.mean(exp_1_opt['pT'])\n",
    "\n",
    "baseline_min = np.min(exp_1_opt['baseline'])\n",
    "T_opt_min = np.min(exp_1_opt['T'])\n",
    "p_opt_min = np.min(exp_1_opt['p'])\n",
    "pT_opt_min = np.min(exp_1_opt['pT'])\n",
    "\n",
    "baseline_max = np.max(exp_1_opt['baseline'])\n",
    "T_opt_max = np.max(exp_1_opt['T'])\n",
    "p_opt_max = np.max(exp_1_opt['p'])\n",
    "pT_opt_max = np.max(exp_1_opt['pT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PERCENTILES = (10,90)\n",
    "per_T_0 = np.percentile(all_t,PERCENTILES[0],axis=0)\n",
    "per_p_0 = np.percentile(all_p,PERCENTILES[0],axis=0)\n",
    "per_pT_0 = np.percentile(all_pT,PERCENTILES[0],axis=0)\n",
    "\n",
    "per_T_1 = np.percentile(all_t,PERCENTILES[1],axis=0)\n",
    "per_p_1 = np.percentile(all_p,PERCENTILES[1],axis=0)\n",
    "per_pT_1 = np.percentile(all_pT,PERCENTILES[1],axis=0)\n",
    "\n",
    "per_T_0_opt = np.percentile(exp_1['T'],PERCENTILES[0],axis=0)\n",
    "per_p_0_opt = np.percentile(exp_1['p'],PERCENTILES[0],axis=0)\n",
    "per_pT_0_opt = np.percentile(exp_1['pT'],PERCENTILES[0],axis=0)\n",
    "\n",
    "per_T_1_opt = np.percentile(exp_1['T'],PERCENTILES[1],axis=0)\n",
    "per_p_1_opt = np.percentile(exp_1['p'],PERCENTILES[1],axis=0)\n",
    "per_pT_1_opt = np.percentile(exp_1['pT'],PERCENTILES[1],axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "T_plot = plt.plot(sizes_sub,means_T, label = 'TS-AUROC', color = 'blue')\n",
    "p_plot = plt.plot(sizes_sub,means_p, label = 'pNormSoftmax', color = 'red')\n",
    "pT_plot = plt.plot(sizes_sub,means_pT, label = 'pNormSoftmax*', color = 'green')\n",
    "\n",
    "#plt.fill_between(sizes_sub, min_p, max_p, facecolor=p_plot[0].get_color(), alpha=0., label = 'min-max')\n",
    "#plt.fill_between(sizes_sub, min_pT, max_pT, facecolor='pT_plot[0].get_color(), alpha=0.5, label = 'min-max')\n",
    "\n",
    "plt.fill_between(sizes_sub, per_p_0, per_p_1, facecolor=p_plot[0].get_color(), alpha=0.3)\n",
    "plt.fill_between(sizes_sub, per_T_0, per_T_1, facecolor=T_plot[0].get_color(), alpha=0.3)\n",
    "plt.fill_between(sizes_sub, per_pT_0, per_pT_1, facecolor=pT_plot[0].get_color(), alpha=0.3)\n",
    "\n",
    "plt.axhline(baseline_mean,linestyle = '--', color = 'k')\n",
    "plt.axhline(T_opt_mean,linestyle = '--', color = T_plot[0].get_color())\n",
    "plt.axhline(p_opt_mean,linestyle = '--', color = p_plot[0].get_color())\n",
    "plt.axhline(pT_opt_mean,linestyle = '--', color = pT_plot[0].get_color())\n",
    "\n",
    "plt.axhline(per_pT_0_opt,linestyle = ':', color = pT_plot[0].get_color(),linewidth = 1.0)\n",
    "plt.axhline(per_pT_1_opt,linestyle = ':', color = pT_plot[0].get_color(),linewidth = 1.0)\n",
    "\n",
    "plt.axhline(per_T_0_opt,linestyle = ':', color = T_plot[0].get_color(),linewidth = 1.0)\n",
    "plt.axhline(per_T_1_opt,linestyle = ':', color = T_plot[0].get_color(),linewidth = 1.0)\n",
    "\n",
    "plt.axhline(per_p_0_opt,linestyle = ':', color = p_plot[0].get_color(),linewidth = 1.0)\n",
    "plt.axhline(per_p_1_opt,linestyle = ':', color = p_plot[0].get_color(),linewidth = 1.0)\n",
    "\n",
    "#plt.ylim(0.858,0.876)\n",
    "plt.xlim(0,right=5000)\n",
    "plt.xlabel('Hold-out Samples')\n",
    "plt.ylabel('Test AUROC')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig(os.path.join(FIGS_PATH, f'DataEfficiency_{MODEL_ARC}.pdf'), transparent = True, format = 'pdf',bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
